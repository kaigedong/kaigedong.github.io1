<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#33363b">
    <meta name="msapplication-TileColor" content="#33363b">
    
    
    
    <meta name="keywords" content="Life, ARIA, Hexo">
    
    
    <link rel="apple-touch-icon" sizes="180x180" href="/favicons/apple-touch-icon.png">
    
    
    <link rel="icon" type="image/png" sizes="192x192" href="/favicons/android-chrome-192x192.png">
    
    
    <link rel="icon" type="image/png" sizes="32x32" href="/favicons/favicon-32x32.png">
    
    
    <link rel="icon" type="image/png" sizes="16x16" href="/favicons/favicon-16x16.png">
    
    
    <link rel="mask-icon" href="/favicons/safari-pinned-tab.svg" color="#33363b">
    
    
    <link rel="manifest" href="/favicons/site.webmanifest">
    
    
    <meta name="msapplication-config" content="/favicons/browserconfig.xml">
    
    
    <link rel="alternate" href="/atom.xml" title="读书笔记" type="application/atom+xml" />
    
    
    <link rel="shortcut icon" type="image/x-icon" href="/favicons/favicon.ico">
    
    
    <link rel="stylesheet" type="text/css" href="/css/normalize.css">
    <link rel="stylesheet" type="text/css" href="/css/index.css">
    
    <link rel="stylesheet" type="text/css" href="/css/sidebar.css">
    
    
<link rel="stylesheet" type="text/css" href="/css/page.css">
<link rel="stylesheet" type="text/css" href="/css/post.css">

    <link rel="stylesheet" type="text/css" href="/css/custom.css">
    <link rel="stylesheet" type="text/css" href="/css/atom-one-dark.css">
    <link rel="stylesheet" type="text/css" href="/css/lightgallery.min.css">
    <script type="text/javascript" src="/js/jquery.min.js"></script>
    <script defer type="text/javascript" src="/js/util.js"></script>
    <script defer type="text/javascript" src="/js/scrollspy.js"></script>
    <script defer type="text/javascript" src="/js/fontawesome-all.min.js"></script>
    <script defer type="text/javascript" src="/js/lightgallery.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-fullscreen.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-hash.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-pager.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-thumbnail.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-zoom.min.js"></script>
    
    <script defer src="/js/busuanzi.pure.mini.js"></script>
    
    
    <script defer type="text/javascript" src="/js/search.js"></script>
    <script type="text/javascript">
    $(document).ready(function () {
      var searchPath = "search.xml";
      if (searchPath.length === 0) {
        searchPath = "search.xml";
      }
      var path = "/" + searchPath;
      searchFunc(path, "search-input", "search-result");
    });
    </script>
    
    
    <script defer type="text/javascript" src="/js/index.js"></script>
    
    <script defer type="text/javascript" src="/js/custom.js"></script>
    <title>pytorch:CNN卷积神经网络 | 读书笔记</title>
  </head>
  <body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"  data-spy="scroll" data-target=".list-group">
    
<header id="header" class="header" style="background: #33363b;">
  <div class="container">
    <div class="header-container">
      <div class="header-title">
        <h1 class="title"><a href="/">读书笔记</a></h1>
        <h2 class="subtitle"></h2>
      </div>
      
      <div class="logo">
        <img src="/images/my_logo.png" alt="logo">
      </div>
      
    </div>
    
<nav id="nav" class="nav">
  <a id="nav-toggle" class="nav-toggle" aria-hidden="true"><i class="fas fa-bars" aria-label="切换导航栏"></i></a>
  <ul id="menu" role="menubar" aria-hidden="false">
    
    <li role="menuitem"><a href="/">首页</a></li>
    
    <li role="menuitem"><a href="/archives/">归档</a></li>
    
    <li role="menuitem"><a href="/categories/">分类</a></li>
    
    <li role="menuitem"><a href="/tags/">标签</a></li>
    
    <li role="menuitem"><a href="/about/">关于</a></li>
    
  </ul>
</nav>


  </div>
</header>


    <main id="main" class="main">
      <div class="container">
        <div class="main-container">
          <div class="content">
            
<div id="post" class="post">
  
  <article class="post-article card animate" itemscope itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/23/pytorch-CNN卷积神经网络/">
      <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
       <meta itemprop="name" content="Kaige Dong">
       <meta itemprop="description" content="">
       <meta itemprop="image" content="/images/myavatar.png">
      </span>
      <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
       <meta itemprop="name" content="读书笔记">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">pytorch:CNN卷积神经网络</h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2017-09-23T14:57:40+08:00">2017-09-23 14:57:40</time></span>
        </span>
        
        
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-comment-count">
          <i class="far fa-comments"></i><span><a href="/2017/09/23/pytorch-CNN卷积神经网络/#disqus_thread" itemprop="discussionUrl"><span class="post-comment-count disqus-comment-count" data-disqus-identifier="2017/09/23/pytorch-CNN卷积神经网络/" itemprop="commentCount"></span></a></span>
        </span>
        
        
      </div>
    </header>
    <main class="post-main" itemprop="articleBody">
      <p>卷积神经网络目前被广泛地用在图片识别上, 已经有层出不穷的应用, 一步一步做一个分析手写数字的 CNN 吧.</p>
<a id="more"></a>
<h2 id="MNIST手写数据"><a href="#MNIST手写数据" class="headerlink" title="MNIST手写数据"></a>MNIST手写数据</h2><figure class="hljs highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable<br><span class="hljs-keyword">import</span> torch.utils.data <span class="hljs-keyword">as</span> Data<br><span class="hljs-keyword">import</span> torchvision      <span class="hljs-comment"># 数据库模块</span><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>torch.manual_seed(<span class="hljs-number">1</span>)    <span class="hljs-comment"># reproducible</span><br><br><span class="hljs-comment"># Hyper Parameters</span><br>EPOCH = <span class="hljs-number">1</span>           <span class="hljs-comment"># 训练整批数据多少次, 为了节约时间, 我们只训练一次</span><br>BATCH_SIZE = <span class="hljs-number">50</span><br>LR = <span class="hljs-number">0.001</span>          <span class="hljs-comment"># 学习率</span><br>DOWNLOAD_MNIST = <span class="hljs-keyword">True</span>  <span class="hljs-comment"># 如果你已经下载好了mnist数据就写上 Fasle</span><br><br><br><span class="hljs-comment"># Mnist 手写数字</span><br>train_data = torchvision.datasets.MNIST(<br>    root=<span class="hljs-string">'./mnist/'</span>,    <span class="hljs-comment"># 保存或者提取位置</span><br>    train=<span class="hljs-keyword">True</span>,  <span class="hljs-comment"># this is training data</span><br>    transform=torchvision.transforms.ToTensor(),    <span class="hljs-comment"># 转换 PIL.Image or numpy.ndarray 成</span><br>                                                    <span class="hljs-comment"># torch.FloatTensor (C x H x W), 训练的时候 normalize 成 [0.0, 1.0] 区间</span><br>    download=DOWNLOAD_MNIST,          <span class="hljs-comment"># 没下载就下载, 下载了就不用再下了</span><br>)<br></code></pre></td></tr></table></figure>
<h3 id="一个数字的例子"><a href="#一个数字的例子" class="headerlink" title="一个数字的例子"></a>一个数字的例子</h3><figure class="hljs highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># plot one example</span><br>print(train_data.train_data.size())                 <span class="hljs-comment"># (60000, 28, 28)</span><br>print(train_data.train_labels.size())               <span class="hljs-comment"># (60000)</span><br>plt.imshow(train_data.train_data[<span class="hljs-number">0</span>].numpy(), cmap=<span class="hljs-string">'gray'</span>)<br>plt.title(<span class="hljs-string">'%i'</span> % train_data.train_labels[<span class="hljs-number">0</span>])<br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="/pic/2017-09/figure_9.png" alt=""></p>
<p>黑色的地方的值都是0, 白色的地方值大于0.</p>
<p>同样, 我们除了训练数据, 还给一些测试数据, 测试看看它有没有训练好.</p>
<figure class="hljs highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">test_data = torchvision.datasets.MNIST(root=<span class="hljs-string">'./mnist/'</span>, train=<span class="hljs-keyword">False</span>)<br><br><span class="hljs-comment"># 批训练 50samples, 1 channel, 28x28 (50, 1, 28, 28)</span><br>train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=<span class="hljs-keyword">True</span>)<br><br><span class="hljs-comment"># 为了节约时间, 我们测试时只测试前2000个</span><br>test_x = Variable(torch.unsqueeze(test_data.test_data, dim=<span class="hljs-number">1</span>), volatile=<span class="hljs-keyword">True</span>).type(torch.FloatTensor)[:<span class="hljs-number">2000</span>]/<span class="hljs-number">255.</span>   <span class="hljs-comment"># shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)</span><br>test_y = test_data.test_labels[:<span class="hljs-number">2000</span>]<br></code></pre></td></tr></table></figure>
<h2 id="CNN-模型"><a href="#CNN-模型" class="headerlink" title="CNN 模型"></a>CNN 模型</h2><p>和以前一样, 我们用一个 class 来建立 CNN 模型. 这个 CNN 整体流程是 卷积(<code>Conv2d</code>) -&gt; 激励函数(<code>ReLU</code>) -&gt; 池化, 向下采样 (<code>MaxPooling</code>) -&gt; 再来一遍 -&gt; 展平多维的卷积成的特征图 -&gt; 接入全连接层 (<code>Linear</code>) -&gt; 输出</p>
<figure class="hljs highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CNN</span><span class="hljs-params">(nn.Module)</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span><br>        super(CNN, self).__init__()<br>        self.conv1 = nn.Sequential(  <span class="hljs-comment"># input shape (1, 28, 28)</span><br>            nn.Conv2d(<br>                in_channels=<span class="hljs-number">1</span>,      <span class="hljs-comment"># input height</span><br>                out_channels=<span class="hljs-number">16</span>,    <span class="hljs-comment"># n_filters</span><br>                kernel_size=<span class="hljs-number">5</span>,      <span class="hljs-comment"># filter size</span><br>                stride=<span class="hljs-number">1</span>,           <span class="hljs-comment"># filter movement/step</span><br>                padding=<span class="hljs-number">2</span>,      <span class="hljs-comment"># 如果想要 con2d 出来的图片长宽没有变化, padding=(kernel_size-1)/2 当 stride=1</span><br>            ),      <span class="hljs-comment"># output shape (16, 28, 28)</span><br>            nn.ReLU(),    <span class="hljs-comment"># activation</span><br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),    <span class="hljs-comment"># 在 2x2 空间里向下采样, output shape (16, 14, 14)</span><br>        )<br>        self.conv2 = nn.Sequential(  <span class="hljs-comment"># input shape (1, 28, 28)</span><br>            nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>),  <span class="hljs-comment"># output shape (32, 14, 14)</span><br>            nn.ReLU(),  <span class="hljs-comment"># activation</span><br>            nn.MaxPool2d(<span class="hljs-number">2</span>),  <span class="hljs-comment"># output shape (32, 7, 7)</span><br>        )<br>        self.out = nn.Linear(<span class="hljs-number">32</span> * <span class="hljs-number">7</span> * <span class="hljs-number">7</span>, <span class="hljs-number">10</span>)   <span class="hljs-comment"># fully connected layer, output 10 classes</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span><br>        x = self.conv1(x)<br>        x = self.conv2(x)<br>        x = x.view(x.size(<span class="hljs-number">0</span>), <span class="hljs-number">-1</span>)   <span class="hljs-comment"># 展平多维的卷积图成 (batch_size, 32 * 7 * 7)</span><br>        output = self.out(x)<br>        <span class="hljs-keyword">return</span> output<br><br>cnn = CNN()<br>print(cnn)  <span class="hljs-comment"># net architecture</span><br><span class="hljs-string">"""<br>CNN (<br>  (conv1): Sequential (<br>    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))<br>    (1): ReLU ()<br>    (2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))<br>  )<br>  (conv2): Sequential (<br>    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))<br>    (1): ReLU ()<br>    (2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))<br>  )<br>  (out): Linear (1568 -&gt; 10)<br>)<br>"""</span><br></code></pre></td></tr></table></figure>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>下面我们开始训练, 将 <code>x</code> <code>y</code> 都用 <code>Variable</code> 包起来, 然后放入 <code>cnn</code> 中计算 <code>output</code>, 最后再计算误差. 下面代码省略了计算精确度 <code>accuracy</code> 的部分。</p>
<figure class="hljs highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   <span class="hljs-comment"># optimize all cnn parameters</span><br>loss_func = nn.CrossEntropyLoss()   <span class="hljs-comment"># the target label is not one-hotted</span><br></code></pre></td></tr></table></figure>
<figure class="hljs highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># following function (plot_with_labels) is for visualization, can be ignored if not interested</span><br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> cm<br><span class="hljs-keyword">try</span>: <span class="hljs-keyword">from</span> sklearn.manifold <span class="hljs-keyword">import</span> TSNE; HAS_SK = <span class="hljs-keyword">True</span><br><span class="hljs-keyword">except</span>: HAS_SK = <span class="hljs-keyword">False</span>; print(<span class="hljs-string">'Please install sklearn for layer visualization'</span>)<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_with_labels</span><span class="hljs-params">(lowDWeights, labels)</span>:</span><br>    plt.cla()<br>    X, Y = lowDWeights[:, <span class="hljs-number">0</span>], lowDWeights[:, <span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">for</span> x, y, s <span class="hljs-keyword">in</span> zip(X, Y, labels):<br>        c = cm.rainbow(int(<span class="hljs-number">255</span> * s / <span class="hljs-number">9</span>)); plt.text(x, y, s, backgroundcolor=c, fontsize=<span class="hljs-number">9</span>)<br>    plt.xlim(X.min(), X.max()); plt.ylim(Y.min(), Y.max()); plt.title(<span class="hljs-string">'Visualize last layer'</span>); plt.show(); plt.pause(<span class="hljs-number">0.01</span>)<br><br>plt.ion()<br></code></pre></td></tr></table></figure>
<figure class="hljs highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># training and testing</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(EPOCH):<br>    <span class="hljs-keyword">for</span> step, (x, y) <span class="hljs-keyword">in</span> enumerate(train_loader):   <span class="hljs-comment"># 分配 batch data, normalize x when iterate train_loader</span><br>        b_x = Variable(x)   <span class="hljs-comment"># batch x</span><br>        b_y = Variable(y)   <span class="hljs-comment"># batch y</span><br><br>        output = cnn(b_x)               <span class="hljs-comment"># cnn output</span><br>        loss = loss_func(output, b_y)   <span class="hljs-comment"># cross entropy loss</span><br>        optimizer.zero_grad()           <span class="hljs-comment"># clear gradients for this training step</span><br>        loss.backward()                 <span class="hljs-comment"># backpropagation, compute gradients</span><br>        optimizer.step()                <span class="hljs-comment"># apply gradients</span><br>        <br>        <span class="hljs-keyword">if</span> step % <span class="hljs-number">50</span> == <span class="hljs-number">0</span>:<br>            test_output, last_layer = cnn(test_x)<br>            pred_y = torch.max(test_output, <span class="hljs-number">1</span>)[<span class="hljs-number">1</span>].data.squeeze()<br>            accuracy = sum(pred_y == test_y) / float(test_y.size(<span class="hljs-number">0</span>))<br>            print(<span class="hljs-string">'Epoch: '</span>, epoch, <span class="hljs-string">'| train loss: %.4f'</span> % loss.data[<span class="hljs-number">0</span>], <span class="hljs-string">'| test accuracy: %.2f'</span> % accuracy)<br>            <span class="hljs-keyword">if</span> HAS_SK:<br>                <span class="hljs-comment"># Visualization of trained flatten layer (T-SNE)</span><br>                tsne = TSNE(perplexity=<span class="hljs-number">30</span>, n_components=<span class="hljs-number">2</span>, init=<span class="hljs-string">'pca'</span>, n_iter=<span class="hljs-number">5000</span>)<br>                plot_only = <span class="hljs-number">500</span><br>                low_dim_embs = tsne.fit_transform(last_layer.data.numpy()[:plot_only, :])<br>                labels = test_y.numpy()[:plot_only]<br>                plot_with_labels(low_dim_embs, labels)<br>plt.ioff()<br><br><span class="hljs-string">"""<br>...<br>Epoch:  0 | train loss: 0.0306 | test accuracy: 0.97<br>Epoch:  0 | train loss: 0.0147 | test accuracy: 0.98<br>Epoch:  0 | train loss: 0.0427 | test accuracy: 0.98<br>Epoch:  0 | train loss: 0.0078 | test accuracy: 0.98<br>"""</span><br></code></pre></td></tr></table></figure>
<p>最后我们再来取10个数据, 看看预测的值到底对不对:</p>
<figure class="hljs highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">test_output = cnn(test_x[:<span class="hljs-number">10</span>])<br>pred_y = torch.max(test_output, <span class="hljs-number">1</span>)[<span class="hljs-number">1</span>].data.numpy().squeeze()<br>print(pred_y, <span class="hljs-string">'prediction number'</span>)<br>print(test_y[:<span class="hljs-number">10</span>].numpy(), <span class="hljs-string">'real number'</span>)<br><br><span class="hljs-string">"""<br>[7 2 1 0 4 1 4 9 5 9] prediction number<br>[7 2 1 0 4 1 4 9 5 9] real number<br>"""</span><br></code></pre></td></tr></table></figure>

    </main>
    <footer class="post-footer">
      
    </footer>
  </article>
  
  
  <div class="post-nav">
    <div class="post-nav-next post-nav-item">
      
      <a href="/2017/09/23/pytorch-Optimizer优化器/" rel="next" title="pytorch:Optimizer优化器"><i class="fas fa-angle-left"></i><span class="nav-title">pytorch:Optimizer优化器</span></a>
      
    </div>
    <div class="post-nav-prev post-nav-item">
      
      <a href="/2017/09/25/Adapter-and-quality-trimming-of-illumina-data/" rel="prev" title="Adapter and quality trimming of illumina data"><span class="nav-title">Adapter and quality trimming of illumina data</span><i class="fas fa-angle-right"></i></a>
      
    </div>
  </div>
  
  
  

<div class="comments" id="comments">
  
  <script defer id="dsq-count-scr" src="//kaigedong.disqus.com/count.js"></script>
  
  <div id="disqus_thread" class="disqus_thread"></div>
  <script type="text/javascript">
  var disqus_config = function () {
    this.page.url = "http://yoursite.com/2017/09/23/pytorch-CNN卷积神经网络/";
    this.page.identifier = "2017/09/23/pytorch-CNN卷积神经网络/";
  };
  (function() {
    var d = document, s = d.createElement("script");
    s.src = "https://kaigedong.disqus.com/embed.js";
    s.setAttribute("data-timestamp", +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  
  
</div>



  
</div>

          </div>
          
          
          
<aside class="sidebar" id="sidebar" style="background: url(/images/sidebar_background.png);">
  
  <div class="search">
    <div class="form-group">
      <i class="fas fa-search"></i><input type="search" id="search-input" name="q" results="0" placeholder="搜索" class="form-control"/>
    </div>
  </div>
  <div class="search-result-box" id="search-result"></div>
  
  
<div class="info sidebar-item" id="info">
  
  <img class="author-avatar" src="/images/myavatar.png" alt="Kaige Dong">
  
  <h1 class="author-name">Kaige Dong</h1>
  <h2 class="author-description"></h2>
  <div class="site-count">
    
    <div class="archives-count">
      <div class="site-count-title">归档</div>
      <div><a href="/archives/">59</a></div>
    </div>
    
    
    
    <span class="site-count-divider divider">|</span>
    
    <div class="categories-count">
      <div class="site-count-title">分类</div>
      <div><a href="/categories/">0</a></div>
    </div>
    
    
    
    <span class="site-count-divider divider">|</span>
    
    <div class="tags-count">
      <div class="site-count-title">标签</div>
      <div><a href="/tags/">12</a></div>
    </div>
    
  </div>
  
  <div class="rss">
    <a class="rss-link button sidebar-item" href="/atom.xml"><i class="fas fa-rss"></i>RSS</a>
  </div>
  
</div>


  <div class="sidebar-sticky">
    
    




<hr>
<div class="post-toc sidebar-item" id="toc-div">
  <div><i class="fas fa-list-ol"></i>文章目录</div>
  <div class="post-toc-content"><ol class="list-group toc"><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#MNIST手写数据"><span class="toc-text">MNIST手写数据</span></a><ol class="list-group toc-child"><li class="toc-item toc-level-3"><a class="list-group-item toc-link" href="#一个数字的例子"><span class="toc-text">一个数字的例子</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#CNN-模型"><span class="toc-text">CNN 模型</span></a></li><li class="toc-item toc-level-2"><a class="list-group-item toc-link" href="#训练"><span class="toc-text">训练</span></a></li></ol></div>
</div>



    
    
    
<hr>
<div class="social-link sidebar-item">
  <div><i class="far fa-address-card"></i>社交链接</p></div>
  <ul>
    
    <li><i class="fas fa-envelope"></i><a href="mailto:dongkaige@gmail.com" target="_blank">E-Mail</a></li>
    
    <li><i class="fab fa-github"></i><a href="https://github.com/kaigedong" target="_blank">GitHub</a></li>
    
    <li><i class="fab fa-weibo"></i><a href="https://weibo.com/u/2264075493" target="_blank">Weibo</a></li>
    
  </ul>
</div>


    
    
    
<hr>
<div class="blogroll sidebar-item">
  <div><i class="fas fa-link"></i>友情链接</div>
  <ul>
    
    <li><a href="https://github.com/" target="_blank">Yiweiniu's GitHub</a></li>
    
    <li><a href="https://developer.mozilla.org/" target="_blank">MDN</a></li>
    
    <li><a href="https://mozilla.github.io/nunjucks/" target="_blank">Nunjucks</a></li>
    
  </ul>
</div>


    
  </div>
</aside>


          
        </div>
      </div>
    </main>
    
<footer id="footer" class="footer" style="background: #33363b;">
  <div class="container">
    <div class="back-to-top">
      <button id="back-to-top"><i class="fas fa-angle-double-up" aria-label="回到顶部"></i></button>
    </div>
    <div class="footer-container">
      <div class="footer-left">
        <div class="copyright">
          <span class="author">Kaige Dong</span><span class="year"><i class="far fa-copyright"></i>2016 - 2018</span>
        </div>
        
        
<div class="busuanzi">
  <span id="busuanzi_container_site_pv"><i class="fas fa-eye" aria-label="站点点击量" aria-hidden="false"></i><span id="busuanzi_value_site_pv"></span></span><span id="busuanzi_container_site_uv"><i class="fas fa-user" aria-label="站点用户数" aria-hidden="false"></i><span id="busuanzi_value_site_uv"></span></span><span id="busuanzi_container_page_pv"><i class="far fa-file-alt"></i><span id="busuanzi_value_page_pv" aria-label="页面点击量" aria-hidden="false"></span></span>
</div>


        
      </div>
      <div class="footer-right">
        <div class="custom-info">
          
          托管于<i class="fab fa-github-alt"></i><a href="https://pages.github.com/" target="_blank">GitHub Pages</a>
          
        </div>
        <div class="powered-by">
          由 <a href="https://hexo.io/" target="_blank">Hexo</a> 强力驱动 | 主题 <a href="https://github.com/AlynxZhou/hexo-theme-aria/" target="_blank">ARIA</a>
        </div>
      </div>
    </div>
  </div>
</footer>


  </body>
</html>
